{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fe046c",
   "metadata": {},
   "source": [
    "We are going to create a convolutional neural network capable of recognizing handwritten digits! \n",
    "\n",
    "The principle is simple:\n",
    "using a dataset of images containing handwritten digits (annotated with the corresponding digit labels), provided by Keras (a deep learning framework), we will train three different models( three different architectures) and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a280d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    " \n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "394d7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_first')\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2a6410",
   "metadata": {},
   "source": [
    "Setting the seed in machine learning is important for reproducibility: Machine learning models often involve randomness, such as initializing weights, shuffling datasets, or splitting data into training and validation sets.By setting the seed, the randomness is controlled, and you can reproduce the same results each time you run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6e95a",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb0b1239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]\n",
      "\n",
      " [[0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]\n",
      "  [0 0 0 ... 0 0 0]]]\n",
      "(60000, 28, 28)\n",
      "[5 0 4 ... 5 6 8]\n",
      "(60000,)\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "(X_train, y_train),(X_test, y_test)= mnist.load_data()\n",
    "print (X_train)\n",
    "print (X_train.shape)\n",
    "print (y_train)\n",
    "print (y_train.shape)\n",
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "408833c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "X_train= X_train/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b68fd6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to be [samples][channels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28,28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "456514ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#one hot encode outputs\n",
    "#converting class vectors to binary class matrices. Each label is converted into a binary matrix representation :\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "#calculate the number of classes in the classification task\n",
    "num_classes = y_test.shape[1]\n",
    "print(num_classes)\n",
    "print (y_test)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f318ef",
   "metadata": {},
   "source": [
    "One-Hot Encoding: In machine learning, especially in classification tasks, it's common to represent categorical labels using one-hot encoding.It transforms categorical labels into a binary matrix representation, where each class is represented by a binary vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ef3c3",
   "metadata": {},
   "source": [
    "## Build the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af601f",
   "metadata": {},
   "source": [
    "### 1.Small Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9f18f",
   "metadata": {},
   "source": [
    "Our goal is to have successively:\n",
    "\n",
    " A convolution with 64 filters in 3×3(for detecting patterns and features) followed by a ReLU activation layer(introduces non-linearity by replacing all negative pixel values in the feature map with zero)\n",
    "\n",
    " A convolution with 32 filters in 3×3 followed by a ReLU activation layer\n",
    "\n",
    " A flatten layer that transforms the 2D feature maps into a 1D vector that can be fed into a traditional artificial neural network.s.\n",
    "\n",
    " A dense layer, an artificial neural network with 10 neurons, followed by a softmax to make predictions based on the features learned from the convolutional layers\n",
    "The 10 neurons in the output layer correspond to the possible classes ( digits 0 through 9). The softmax activation function is used to convert the network's raw output into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37be7f42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 106s 348ms/step - loss: 0.2340 - accuracy: 0.9345 - val_loss: 0.0696 - val_accuracy: 0.9784\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 104s 345ms/step - loss: 0.0652 - accuracy: 0.9797 - val_loss: 0.0445 - val_accuracy: 0.9852\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 102s 341ms/step - loss: 0.0434 - accuracy: 0.9866 - val_loss: 0.0394 - val_accuracy: 0.9870\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 102s 341ms/step - loss: 0.0336 - accuracy: 0.9895 - val_loss: 0.0437 - val_accuracy: 0.9862\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 104s 348ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.0426 - val_accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 104s 348ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.0437 - val_accuracy: 0.9864\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 104s 346ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 102s 339ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0507 - val_accuracy: 0.9856\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 101s 338ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0435 - val_accuracy: 0.9884\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 105s 349ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0541 - val_accuracy: 0.9871\n",
      "<keras.callbacks.History object at 0x0000022109F79D00>\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(1, 28, 28), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#compile model\n",
    "model.compile(  optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "history= model.fit(X_train, y_train, epochs=10, batch_size=200, validation_data=(X_test, y_test))\n",
    "print (history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb1d575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score : 98.71%\n",
      "Model error rate : 1.29%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Model score : %.2f%%\" % (scores[1]*100))\n",
    "print(\"Model error rate : %.2f%%\" % (100-scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b561b1",
   "metadata": {},
   "source": [
    "### 2.Medium Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79eefa0",
   "metadata": {},
   "source": [
    "defined as follows:\n",
    "\n",
    "A convolution with 32 filters in 5×5 with a ReLU activation .\n",
    "\n",
    "A 2×2 max-pooling.\n",
    "\n",
    "A dropout of 0.2\n",
    "\n",
    "A flatten layer.\n",
    "\n",
    "A dense layer with 128 outputs and ReLU activation.\n",
    "\n",
    "A final dense layer with 10 outputs and softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e8db170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 52s 170ms/step - loss: 0.2139 - accuracy: 0.9386 - val_loss: 0.0688 - val_accuracy: 0.9792\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 50s 167ms/step - loss: 0.0631 - accuracy: 0.9816 - val_loss: 0.0427 - val_accuracy: 0.9855\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 51s 169ms/step - loss: 0.0436 - accuracy: 0.9868 - val_loss: 0.0368 - val_accuracy: 0.9881\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 49s 163ms/step - loss: 0.0330 - accuracy: 0.9897 - val_loss: 0.0343 - val_accuracy: 0.9881\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 48s 159ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 0.0362 - val_accuracy: 0.9872\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 48s 161ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0328 - val_accuracy: 0.9888\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 48s 159ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0368 - val_accuracy: 0.9883\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 48s 160ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0338 - val_accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 48s 160ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0339 - val_accuracy: 0.9894\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 49s 163ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0371 - val_accuracy: 0.9887\n",
      "<keras.callbacks.History object at 0x000002210D783F10>\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='ReLU'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#compile model\n",
    "model.compile(  optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "history= model.fit(X_train, y_train, epochs=10, batch_size=200, validation_data=(X_test, y_test))\n",
    "print (history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92485446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score : 98.87%\n",
      "Model error rate : 1.13%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Model score : %.2f%%\" % (scores[1]*100))\n",
    "print(\"Model error rate : %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a058f9c3",
   "metadata": {},
   "source": [
    "### 3.Large Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e718dc",
   "metadata": {},
   "source": [
    "Defined as follows:\n",
    "\n",
    "A convolution with 30 filters of size 5x5 with ReLU activation \n",
    "\n",
    "A max-pooling layer of size 2x2\n",
    "\n",
    "A convolution with 15 filters of size 3x3 with ReLU\n",
    "\n",
    "A dropout of 0.2\n",
    "\n",
    "A flatten layer\n",
    "\n",
    "A dense layer with 128 outputs and ReLU activation\n",
    "\n",
    "A dense layer with 50 outputs and ReLU activation\n",
    "\n",
    "A dense layer with 10 outputs and softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae248473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 [==============================] - 32s 102ms/step - loss: 0.3040 - accuracy: 0.9073 - val_loss: 0.0661 - val_accuracy: 0.9792\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 31s 102ms/step - loss: 0.0733 - accuracy: 0.9773 - val_loss: 0.0500 - val_accuracy: 0.9837\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 30s 99ms/step - loss: 0.0508 - accuracy: 0.9844 - val_loss: 0.0333 - val_accuracy: 0.9890\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 30s 100ms/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.0337 - val_accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 30s 101ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 0.0366 - val_accuracy: 0.9879\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 30s 99ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 0.0255 - val_accuracy: 0.9923\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 30s 100ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.0298 - val_accuracy: 0.9899\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 29s 98ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0270 - val_accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 31s 103ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0342 - val_accuracy: 0.9891\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 30s 99ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0304 - val_accuracy: 0.9907\n",
      "<keras.callbacks.History object at 0x000002210DB0B8E0>\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(15, (3,3), input_shape=(1, 28, 28), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='ReLU'))\n",
    "model.add(Dense(50, activation='ReLU'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#compile model\n",
    "model.compile(  optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "history= model.fit(X_train, y_train, epochs=10, batch_size=200, validation_data=(X_test, y_test))\n",
    "print (history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "630e2752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score : 99.07%\n",
      "Model error rate : 0.93%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Model score : %.2f%%\" % (scores[1]*100))\n",
    "print(\"Model error rate : %.2f%%\" % (100-scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
